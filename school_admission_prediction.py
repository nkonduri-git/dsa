# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qIoL1EBvP3o-RLOujKtBQl9FjJjewoQ_
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

# %matplotlib inline
sns.set()
warnings.simplefilter('ignore')

data = pd.read_csv('Admission_Predict_Ver1.1.csv')

df = data.copy()
df.tail(20)

df.drop('Serial No.', axis=1, inplace=True)
df.head()

df.isnull().sum()

df.dtypes

df.describe()

df.columns = df.columns.str.strip()
df.columns

# Checking the correlation coefficient of GRE Score with Chance of Admit
df[['GRE Score', 'Chance of Admit']].corr()

plt.figure(figsize=(10, 6))
sns.regplot(x='GRE Score', y='Chance of Admit', data=df)

from scipy import stats


p_coeff, p_value = stats.pearsonr(df['GRE Score'], df['Chance of Admit'])
print('Pearson Coefficient:', p_coeff)
print('P Value:            ', p_value)

# Checking the correlation-coefficient
df[['TOEFL Score', 'Chance of Admit']].corr()

plt.figure(figsize=(10, 6))
sns.regplot(data=df, x='TOEFL Score', y='Chance of Admit')

p_coeff, p_value = stats.pearsonr(df['TOEFL Score'], df['Chance of Admit'])
print('Pearson Coefficient:', p_coeff)
print('Pearson Value:      ', p_value)

plt.figure(figsize=(10, 6))
sns.regplot(x=df['University Rating'], y=df['Chance of Admit'])

plt.figure(figsize=(10, 6))
sns.boxplot(data=df, x='University Rating', y='Chance of Admit')

df[['University Rating', 'Chance of Admit']].corr()

coef, pvalue = stats.pearsonr(df['University Rating'], df['Chance of Admit'])
coef, pvalue

df_rating_grp = df[['University Rating', 'Chance of Admit']].groupby(['University Rating'])

f, pvalue = stats.f_oneway(df_rating_grp.get_group(1)['Chance of Admit'],
                           df_rating_grp.get_group(2)['Chance of Admit'],
                           df_rating_grp.get_group(3)['Chance of Admit'],
                           df_rating_grp.get_group(4)['Chance of Admit'],
                           df_rating_grp.get_group(5)['Chance of Admit'])

print('f oneway:', f, '\nP Value:', pvalue)

plt.figure(figsize=(10, 6))
sns.regplot(data=df, x='SOP', y='Chance of Admit')

df[['SOP', 'Chance of Admit']].corr()

plt.figure(figsize=(10, 6))
sns.boxplot(data=df, x='SOP', y='Chance of Admit')

p_coeff, pvalue = stats.pearsonr(df.SOP, df['Chance of Admit'])

print('Pearson Coefficient: ', p_coeff)
print('P Value:             ', pvalue)

df_sop_grp = df[['SOP', 'Chance of Admit']].groupby(['SOP'])


f, pvalue = stats.f_oneway(df_sop_grp.get_group(1.0)['Chance of Admit'],
                          df_sop_grp.get_group(1.5)['Chance of Admit'],
                          df_sop_grp.get_group(2.0)['Chance of Admit'],
                          df_sop_grp.get_group(2.5)['Chance of Admit'],
                          df_sop_grp.get_group(3.0)['Chance of Admit'],
                          df_sop_grp.get_group(3.5)['Chance of Admit'],
                          df_sop_grp.get_group(4.0)['Chance of Admit'],
                          df_sop_grp.get_group(4.5)['Chance of Admit'],
                          df_sop_grp.get_group(5.0)['Chance of Admit'])

f, pvalue

plt.figure(figsize=(10, 6))
sns.regplot(x=df.LOR, y=df['Chance of Admit'])

df[['LOR', 'Chance of Admit']].corr()

p_coeff, pvalue = stats.pearsonr(df.LOR, df['Chance of Admit'])

p_coeff, pvalue

df_lor_grp = df[['LOR', 'Chance of Admit']].groupby('LOR')


f, pvalue = stats.f_oneway(df_lor_grp.get_group(1.0)['Chance of Admit'],
                          df_lor_grp.get_group(1.5)['Chance of Admit'],
                          df_lor_grp.get_group(2.0)['Chance of Admit'],
                          df_lor_grp.get_group(2.5)['Chance of Admit'],
                          df_lor_grp.get_group(3.0)['Chance of Admit'],
                          df_lor_grp.get_group(3.5)['Chance of Admit'],
                          df_lor_grp.get_group(4.0)['Chance of Admit'],
                          df_lor_grp.get_group(4.5)['Chance of Admit'],
                          df_lor_grp.get_group(5.0)['Chance of Admit'])

f, pvalue

plt.figure(figsize=(10, 6))
sns.regplot(x=df.CGPA, y=df['Chance of Admit'])

df[['CGPA', 'Chance of Admit']].corr()

p_coeff, pvalue = stats.pearsonr(df.CGPA, df['Chance of Admit'])

p_coeff, pvalue

plt.figure(figsize=(10, 6))
sns.regplot(x=df.Research, y=df['Chance of Admit'])

df[['Research', 'Chance of Admit']].corr()

plt.figure(figsize=(5, 6))
sns.countplot(x=df.Research)

plt.figure(figsize=(10, 6))
sns.boxplot(x=df.Research, y=df['Chance of Admit'])

df_res_grp = df[['Research', 'Chance of Admit']].groupby('Research')


f, pvalue = stats.f_oneway(df_res_grp.get_group(1)['Chance of Admit'],
                           df_res_grp.get_group(0)['Chance of Admit'])
f, pvalue

plt.figure(figsize=(15, 6))
sns.heatmap(data=df.corr(), annot=True)

plt.figure(figsize=(10, 6))
plt.title('Relationship between CGPA and GRE Score', fontsize=15)
plt.xlabel('', fontsize=15)
plt.ylabel('', fontsize=15)
sns.regplot(x=df['GRE Score'], y=df.CGPA)

plt.figure(figsize=(10, 6))
sns.scatterplot(x=df['GRE Score'], y=df.CGPA, hue=df['Chance of Admit'])
plt.title('Relationship between CGPA and GRE Score', fontsize=15)
plt.xlabel('GRE Score', fontsize=15)
plt.ylabel('CGPA', fontsize=15)
plt.show()

X = df.drop('Chance of Admit', axis=1)
Y = df[['Chance of Admit']]

X.shape, Y.shape

# Importing train_test_split
from sklearn.model_selection import train_test_split

xtrain, xtest, ytrain, ytest = train_test_split(
    X, Y, random_state=42, shuffle=True, test_size=0.30)

print(xtrain.shape, ytrain.shape)
print(xtest.shape, ytest.shape)

from sklearn.linear_model import LassoCV

lasso = LassoCV(random_state=42, n_jobs=4)

lasso.fit(xtrain, ytrain)
regularized_model_prediction = lasso.predict(xtest)

from sklearn.metrics import r2_score


r2_score(ytest, regularized_model_prediction)

from sklearn.preprocessing import PolynomialFeatures


# Checking the degree of polynomial from 1 to 6
train_r2_scores = []
test_r2_scores = []
for degree in range(1, 7):
    # Converting the features to polynomial
    model_poly = PolynomialFeatures(degree=degree)
    xtrain_poly, xtest_poly = model_poly.fit_transform(xtrain), model_poly.fit_transform(xtest)

    # Initializing LassoCV
    model_lasso = LassoCV(random_state=42, n_jobs=4, cv=5)
    model_lasso.fit(xtrain_poly, ytrain)

    # Getting the training score in the list
    train_r2_scores.append(r2_score(ytrain, model_lasso.predict(xtrain_poly)))
    test_r2_scores.append(r2_score(ytest, model_lasso.predict(xtest_poly)))

# Displaying the model complexity
plt.figure(figsize=(10, 7))
sns.lineplot(x=range(1, 7), y=train_r2_scores, label='Training')
sns.lineplot(x=range(1, 7), y=test_r2_scores, label='Testing')
plt.xlabel('Degrees', fontsize=15)
plt.ylabel('R-Squared Coef.', fontsize=15)
plt.title('Model Complexity', fontsize=15)
plt.show()

list(zip(train_r2_scores, test_r2_scores))

from sklearn.linear_model import RidgeCV


# Checking the degree of polynomial from 1 to 6
train_r2_scores = []
test_r2_scores = []
for degree in range(1, 7):
    # Converting the features to polynomial
    model_poly = PolynomialFeatures(degree=degree)
    xtrain_poly, xtest_poly = model_poly.fit_transform(xtrain), model_poly.fit_transform(xtest)

    # Initializing LassoCV
    model_ridge = RidgeCV(cv=5)
    model_ridge.fit(xtrain_poly, ytrain)

    # Getting the training score in the list
    train_r2_scores.append(r2_score(ytrain, model_ridge.predict(xtrain_poly)))
    test_r2_scores.append(r2_score(ytest, model_ridge.predict(xtest_poly)))

# Displaying the model complexity
plt.figure(figsize=(10, 7))
sns.lineplot(x=range(1, 7), y=train_r2_scores, label='Training')
sns.lineplot(x=range(1, 7), y=test_r2_scores, label='Testing')
plt.xlabel('Degrees', fontsize=15)
plt.ylabel('R-Squared Coef.', fontsize=15)
plt.title('Model Complexity', fontsize=15)
plt.show()

list(zip(train_r2_scores, test_r2_scores))

from sklearn.neighbors import KNeighborsRegressor  # Notice here we are taking regressor because we are predicting a continuous variable

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()


scaled = scaler.fit_transform(X)


X = pd.DataFrame(data=scaled, columns=X.columns)
X.head()

model_knn = KNeighborsRegressor()  # Create an instance of the KNeighborsRegressor class
model_knn.fit(xtrain, ytrain)     # Fit the model to the training data

knn_pred_test = model_knn.predict(xtest)


knn_pred_train = model_knn.predict(xtrain)


knn_r2_train = r2_score(ytrain, knn_pred_train)
knn_r2_test = r2_score(ytest, knn_pred_test)


knn_r2_train, knn_r2_test

train_r2_scores = []
test_r2_scores = []

for n in range(1, 30):
    # Initializing KNN
    model_knn = KNeighborsRegressor(n_neighbors=n)

    # Fitting the data and taking predictions for both training and testing dataset
    model_knn.fit(xtrain, ytrain)
    knn_pred_train, knn_pred_test = model_knn.predict(xtrain), model_knn.predict(xtest)

    # Storing the R-Squared Coefficient into list
    train_r2_scores.append(r2_score(ytrain, knn_pred_train))
    test_r2_scores.append(r2_score(ytest, knn_pred_test))


plt.figure(figsize=(15, 7))
sns.lineplot(x=range(1, 30), y=train_r2_scores, label='Training')
sns.lineplot(x=range(1, 30), y=test_r2_scores, label='Testing')
plt.xticks(range(1, 30))

#Checking the degree of polynomial from 1 to 6
train_r2_scores = []
test_r2_scores = []
for degree in range(1, 7):
    # Converting the features to polynomial
    model_poly = PolynomialFeatures(degree=degree)
    xtrain_poly, xtest_poly = model_poly.fit_transform(xtrain), model_poly.fit_transform(xtest)

    # Initializing KNN
    model_knn = KNeighborsRegressor(n_neighbors=11)
    model_knn.fit(xtrain_poly, ytrain)

    # Getting the training score in the list
    train_r2_scores.append(r2_score(ytrain, model_knn.predict(xtrain_poly)))
    test_r2_scores.append(r2_score(ytest, model_knn.predict(xtest_poly)))

# Displaying the model complexity
plt.figure(figsize=(10, 7))
sns.lineplot(x=range(1, 7), y=train_r2_scores, label='Training')
sns.lineplot(x=range(1, 7), y=test_r2_scores, label='Testing')
plt.xlabel('Degrees', fontsize=15)
plt.ylabel('R-Squared Coef.', fontsize=15)
plt.title('Model Complexity', fontsize=15)
plt.yticks([0.7, 0.72, 0.74, 0.76, 0.78, 0.8, 0.82])
plt.show()

list(zip(train_r2_scores, test_r2_scores))